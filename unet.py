# -*- coding: utf-8 -*-
"""UNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qIUXIiy5pi8oATEB8bIxGbLYt3Y-c_p0

inspired from https://analyticsindiamag.com/my-experiment-with-unet-building-an-image-segmentation-model/ and https://www.kaggle.com/c0conuts/unet-imagedatagenerator-lb-0-336
"""

from google.colab import drive
drive.mount('/content/drive')

import cv2
import matplotlib.pyplot as plt
import os
from PIL import Image
import numpy as np
import pandas as pd
import tensorflow as tf
import keras
import PIL.Image as Image

from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.transform import resize
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint


from keras.models import Model, load_model
from keras.layers import Input
from keras.layers.core import Dropout, Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import concatenate
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K

#import tensorflow as tf

def dice_coefficient(y_true, y_pred):
  numerator = 2 * tf.reduce_sum(y_true * y_pred)
  denominator = tf.reduce_sum(y_true + y_pred)
  return numerator / (denominator + tf.keras.backend.epsilon())

# Set some parameters
BATCH_SIZE = 32 # the higher the better
IMG_WIDTH = 128 # for faster computing on kaggle
IMG_HEIGHT =128 # for faster computing on kaggle
IMG_CHANNELS = 3
seed = 42

"""# Import data"""

code_dir='/content/drive/MyDrive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/UNet'

masks_dir=code_dir+'/data/masks'
images_dir=code_dir+'/data/images'
images_list = os.listdir(images_dir)
masks_list = os.listdir(masks_dir)
print(masks_list[:])
print('nb of masks=', len(masks_list), 'nb of images=', len(images_list))

n=np.random.randint(len(images_list))
img_name=images_list[n]
img_path=os.path.join(images_dir,img_name)
img = imread(img_path)[:,:,:IMG_CHANNELS]
#img = img/255
img =cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA) #resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
print('min img=', np.min(img), 'max img=', np.max(img))
print('img shape=', np.shape(img))

fig, (ax1, ax2)=plt.subplots(1,2)
ax1.imshow(img)

#Mask
mask_name=img_name[:-4]+'_road.ome.tiff'
mask_path=os.path.join(masks_dir,mask_name)
mask= imread(mask_path)[:,:]
mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_AREA)# mode='constant', preserve_range=True)

print('min mask=', np.min(mask), 'max mask=', np.max(mask))
print('mask shape=', np.shape(mask))
ax2.imshow(mask)

N=len(masks_list)
Y= np.zeros((N, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool) #np.bool)
X = np.zeros((N,IMG_HEIGHT, IMG_WIDTH,IMG_CHANNELS), dtype=np.float32)

for n in range(N):
  img_name=str(int(n+1))+'.png'
  mask_name=str(int(n+1))+'_road.ome.tiff'
  img_path=os.path.join(images_dir, img_name)
  mask_path=os.path.join(masks_dir, mask_name)
  
  img = imread(img_path)[:,:,:IMG_CHANNELS]
  #img = img/255 #1-img/255
  #img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
  img = cv2.resize(img, ( IMG_WIDTH, IMG_HEIGHT))

  X[n] =img

  mask= imread(mask_path)[:,:]
  mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_AREA ) #resize(mask, (IMG_HEIGHT, IMG_WIDTH,1), mode='constant', preserve_range=True)
  mask=np.reshape(mask,(IMG_HEIGHT, IMG_WIDTH, 1) )
  Y[n] = np.array(mask)

"""Data Augmentation"""

from keras.preprocessing import image

# Creating the training Image and Mask generator
image_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')
mask_datagen = image.ImageDataGenerator(shear_range=0.5, rotation_range=50, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2, fill_mode='reflect')

# Keep the same seed for image and mask generators so they fit together
seed=42
image_datagen.fit(X[:int(X.shape[0]*0.9)], augment=True, seed=seed)
mask_datagen.fit(Y[:int(Y.shape[0]*0.9)], augment=True, seed=seed)

x=image_datagen.flow(X[:int(X.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)
y=mask_datagen.flow(Y[:int(Y.shape[0]*0.9)],batch_size=BATCH_SIZE,shuffle=True, seed=seed)


# Creating the validation Image and Mask generator
image_datagen_val = image.ImageDataGenerator()
mask_datagen_val = image.ImageDataGenerator()

image_datagen_val.fit(X[int(X.shape[0]*0.9):], augment=True, seed=seed)
mask_datagen_val.fit(Y[int(Y.shape[0]*0.9):], augment=True, seed=seed)

x_val=image_datagen_val.flow(X[int(X.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)
y_val=mask_datagen_val.flow(Y[int(Y.shape[0]*0.9):],batch_size=BATCH_SIZE,shuffle=True, seed=seed)

#creating a training and validation generator that generate masks and images
print('train size=', len(x),'; val size=', len(x_val))
train_generator = zip(x, y)
val_generator = zip(x_val, y_val)

"""# Model

## Create
"""

pip install git+https://github.com/karolzak/keras-unet

pip install keras-unet

from sklearn.model_selection import train_test_split
#import tensorflow as tf
from keras.optimizers import Adam
from tensorflow.keras.losses import binary_crossentropy

from keras.layers import Input, Conv2D, Reshape
from keras.models import Model

def dice_coefficient(y_true, y_pred):
  numerator = 2 * tf.reduce_sum(y_true * y_pred)
  denominator = tf.reduce_sum(y_true + y_pred)
  return numerator / (denominator + tf.keras.backend.epsilon())

"""### Import model from keras_unet"""

from keras_unet.models import custom_unet

model = custom_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH,IMG_CHANNELS ),use_batch_norm=False,num_classes=1,filters=64 ,#64 init
    dropout=0.2,
    output_activation='sigmoid')

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])
model.summary()

# Build U-Net model
inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
s = Lambda(lambda x: x / 255) (inputs)

c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)
c1 = Dropout(0.1) (c1)
c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)
p1 = MaxPooling2D((2, 2)) (c1)

c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)
c2 = Dropout(0.1) (c2)
c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)
p2 = MaxPooling2D((2, 2)) (c2)

c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)
c3 = Dropout(0.2) (c3)
c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)
p3 = MaxPooling2D((2, 2)) (c3)

c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)
c4 = Dropout(0.2) (c4)
c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)
p4 = MaxPooling2D(pool_size=(2, 2)) (c4)

c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)
c5 = Dropout(0.3) (c5)
c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)

u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)
u6 = concatenate([u6, c4])
c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)
c6 = Dropout(0.2) (c6)
c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)

u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)
u7 = concatenate([u7, c3])
c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)
c7 = Dropout(0.2) (c7)
c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)

u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)
u8 = concatenate([u8, c2])
c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)
c8 = Dropout(0.1) (c8)
c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)

u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)
u9 = concatenate([u9, c1], axis=3)
c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)
c9 = Dropout(0.1) (c9)
c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)

outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

model = Model(inputs=[inputs], outputs=[outputs])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])
model.summary()

"""### Import Model from directory"""

weight_path='/content/drive/MyDrive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/YOLOv3_TF2/weights/unet.h5'

model=keras.models.load_model(weight_path, custom_objects={'dice_coefficient': dice_coefficient})

"""## Train

### Train with augmentation
"""

# Fit model
earlystopper = EarlyStopping(patience=3, verbose=1)
checkpointer = ModelCheckpoint('UNet.h5', verbose=1, save_best_only=True)
history = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=10, steps_per_epoch=100, epochs=20, callbacks=[earlystopper, checkpointer])

"""### Train without augmentation"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)
print(len(X_train), len(X_test), np.shape(X_train[0]))

history=model.fit(X_train,Y_train,batch_size=BATCH_SIZE ,epochs=10,validation_data=(X_test, Y_test))

"""## Evaluate"""

loss=history.history['loss']; val_loss=history.history['val_loss']
dice=history.history['dice_coefficient']; val_dice=history.history['val_dice_coefficient']

plt.plot(loss,'b-', label='loss')
plt.plot(dice,'b:', label='dice_coefficient')
plt.plot(val_loss,'r-', label='val_loss')
plt.plot(val_dice,'r:', label='val_dice_coefficient')
plt.legend()
plt.xlabel('epochs')

weight_path='/content/drive/MyDrive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/YOLOv3_TF2/weights/unet.h5'
model.save(weight_path)

"""## Predict"""

weight_path='/content/drive/MyDrive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/YOLOv3_TF2/weights/unet.h5'
model=keras.models.load_model(weight_path, custom_objects={'dice_coefficient': dice_coefficient})

def Mask_road(mask, THR=0.5):
  step=6
  M,N=mask.shape[0], mask.shape[1]
  new_mask=np.zeros((M,N))
  S_left, S_right=np.sum(mask[:,:M//2]), np.sum(mask[:,M//2:])
  x_start=(N//2-5)*(S_left>0.5*S_right)+(N//2+20)*(S_left<0.5*S_right)
  first_lane=False
  for y in np.flip(np.arange(0, M-step, step)):
    x1=0; x2=N
    # find left lane
    x=x_start
    while (x>1)*(x1==0):
      if mask[y,x]>THR:
        x1=x
      x-=1
 
    # find right lane
    x=x_start
    while (x<N-1)*(x2==N):
      if mask[y,x]>THR:
        x2=x
      x+=1

    #update mask
    if  (x1!=0)*(x1!=x2) or (x2!=N)*(x1!=x2):
      first_lane=True
      x_start=(x1+x2)//2
      new_mask[y:y+step, x1:x2]=1
    # two consecutive empty rows: end
    else:
      if (y>M//3)*(first_lane==False):
        new_mask[y:y+step, x1:x2]=1
      else:
        return new_mask
  return new_mask

import time
n=np.random.randint(len(images_list))
img_name=images_list[n]
img_path=os.path.join(images_dir, img_name)
img = imread(img_path)[:,:,:IMG_CHANNELS]

fig, (ax1, ax2, ax3)=plt.subplots(1,3,figsize=(15,15))
ax1.imshow(img)
img = imread(img_path)[:,:,:IMG_CHANNELS]
img = cv2.resize(img, ( IMG_WIDTH, IMG_HEIGHT ))
img= np.reshape(img,  (1, IMG_HEIGHT, IMG_WIDTH,IMG_CHANNELS) )
t0=time.perf_counter()
pred_mask=model.predict(img)
t1=time.perf_counter()
pred_mask=np.reshape(pred_mask, (IMG_HEIGHT, IMG_WIDTH))
road=Mask_road(pred_mask)

ax2.imshow(pred_mask>0.5)
ax3.imshow(road)
print(t1-t0)

"""# Produce Masks"""

weight_path='/content/drive/MyDrive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/YOLOv3_TF2/weights/unet.h5'
unet=keras.models.load_model(weight_path, custom_objects={'dice_coefficient': dice_coefficient})

code_dir='/content/drive/MyDrive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/'
images_dir=code_dir+'/data/training_data/training_data/'
masks_dir=code_dir+'/data/training_data/training_masks/'
images_list=os.listdir(images_dir)
N=len(images_list)

INPUT=128

for i in range(1, N):
  if i%500==0:
    print(i, '%')
  id=int(i)
  img_name=str(id)+'.png'
  img_path=images_dir+img_name
  if os.path.isfile(img_path):
    img = imread(img_path)[:,:,:IMG_CHANNELS]
    img = cv2.resize(img, ( IMG_WIDTH, IMG_HEIGHT))
    img=np.reshape(img, (1,INPUT,INPUT,3))
    mask=unet.predict(img)
    mask=np.reshape(mask, (INPUT,INPUT))
    # save numpy array as npy file
    mask_path=masks_dir+str(id)+'.npy'
    np.save(mask_path, mask)

print(N)

"""# Produce road masks + object"""

weight_path='/content/drive/MyDrive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/YOLOv3_TF2/weights/unet.h5'
unet=keras.models.load_model(weight_path, custom_objects={'dice_coefficient': dice_coefficient})

code_dir='/content/drive/MyDrive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/'
images_dir=code_dir+'/data/training_data/training_data/'
masks_dir=code_dir+'/data/training_data/training_masks/'
new_masks_dir=code_dir+'/data/training_data/masks_road_object/'
images_list=os.listdir(images_dir)
N=len(images_list)

boxes_df = pd.read_csv(code_dir+"YOLOv3_TF2/data/prediction_boxes.csv", header=None)
boxes= np.array(boxes_df.values) #box, car, green light, left signal, person, red light, right signal, tree
print(boxes.shape)
print(boxes[0])
box, car, person,  tree=128*boxes[:, 0:4], 128*boxes[:, 4:8], 128*boxes[:, 16:20] , 128*boxes[:, 28:32]
new_boxes=zip(box, car, person,  tree)
print(new_boxes.shape)
print(new_boxes[0])

N=len(images_list)
n=np.random.randint(np.arange(1,N))
id=int(n-1)
mask_name=str(n)+'.npy'
mask_path=masks_dir+mask_name
if os.path.isfile(mask_path):
  mask= np.load(mask_path)
  for box, car, person, tree in new_boxes:

INPUT=128
N=len(images_list)
for i in range(1, N):
  if i%500==0:
    print(i, '%')
  id=int(i)
  img_name=str(id)+'.png'
  img_path=images_dir+img_name
  if os.path.isfile(img_path):
    img = imread(img_path)[:,:,:IMG_CHANNELS]
    img = cv2.resize(img, ( IMG_WIDTH, IMG_HEIGHT))
    img=np.reshape(img, (1,INPUT,INPUT,3))
    mask=unet.predict(img)
    mask=np.reshape(mask, (INPUT,INPUT))
    # save numpy array as npy file
    mask_path=masks_dir+str(id)+'.npy'
    np.save(mask_path, mask)

"""# Draft"""

def Mask_road(mask, THR=0.1):
  step=5
  M,N=mask.shape[0], mask.shape[1]
  new_mask=np.zeros((M,N))
  x_start=N//2 
  prev_x1, prev_x2=0,N
  for y in np.flip(np.arange(0, M-1, step)):
    x1=0; x2=N
    # find left lane
    x=x_start-5
    while (x>1)*(x1==0):
      x-=1
      if mask[y,x]>THR:
        x1=x
    # find right lane
    x=x_start+5
    while (x<N-1)*(x2==N):
      x+=1
      if mask[y,x]>THR:
        x2=x
    #update mask
    if not (x1==0)*(x2==N):
      if (x2>N//2+40)*(x1==0):
        new_mask[y:y+step, :x1]=1
      else:
        new_mask[y:y+step, x1:x2]=1
    # update x_start
    if (x2-x1)<(prev_x2-prev_x1):
      x_start=(x1+x2)//2
    else:
      x_start=(x2+N)//2
      x1, x2=x2, N-1
    prev_x1, prev_x2= x1, x2
    
  return new_mask

def Mask_road(mask, THR=0.3):
  M,N=mask.shape[0], mask.shape[1]
  new_mask=np.zeros((M,N))
  for i in range(M//3, M): #i=rows
    j1, j2 , j3= -1, -1, -1
    j=0
    while (j<N-1)*(j1<0):
      j+=1
      if mask[i,j]>THR:
        j1=j
    j=min(N-1, j+20)
    while (j<N-1)*(j2<0):
      j+=1
      if mask[i,j]>THR:
        j2=j
    j=min(N-1, j+20)
    while (j<N-1)*(j3<0):
      j+=1
      if mask[i,j]>THR:
        j3=j

    if (j1>0)*(j2>0)*(j3>0):
      new_mask[i,j1:j2]=1

    if (j1>0)*(j2>0)*(j3<0):
      if (j1>N//2)*(i>M//2):
        new_mask[i,:j1]=1
      else:
        new_mask[i,j1:j2]=1

    if (j1>0)*(j2<0)*(j3<0):
      new_mask[i,j1:]=1
  return new_mask

from keras.layers import Reshape
N = x_train.shape[-1]

base_model = Unet(backbone_name='resnet34', encoder_weights='imagenet')

input_base_model = Input(shape=(240, 320, N))

l1 = Conv2D(3, (1, 1))(inp)

out = base_model(l1)

x1 = Conv2D(10, kernel_size =3,strides=2,padding = "same", activation="relu")(out)
x1 =layers.BatchNormalization()

x2= Conv2D(10, kernel_size=3,strides=2,padding = "same", activation="relu")(x1)
x2 =layers.BatchNormalization()

x3 = Conv2D(10, kernel_size=3,strides=2,padding = "same", activation="relu")(x2)
x3 =layers.BatchNormalization()

x4 = Conv2D(1, kernel_size=2,strides=2,padding = "same", activation="relu")(x3)

x_out = Reshape((240,320))(x4)

model = Model(input_base_model, x_out, name=base_model.name)



iou=tf.keras.metrics.MeanIoU(num_classes=1, name=None, dtype=None)
model.compile(optimizer='sgd', loss='mse', metrics=[iou])

"""## Evaluate"""



model.evaluate(x_test, y_test)

# Save

model.save('unet.h5')
model=keras.models.load_model('unet.h5')



def dice_coefficient(y_true, y_pred):
  numerator = 2 * tf.reduce_sum(y_true * y_pred)
  denominator = tf.reduce_sum(y_true + y_pred)
  return numerator / (denominator + tf.keras.backend.epsilon())

def loss(y_true, y_pred):
  return binary_crossentropy(y_true, y_pred) - tf.math.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())

model.compile(optimizer='sgd', loss=loss, metrics=[dice_coefficient])
#iou=tf.keras.metrics.MeanIoU(num_classes=1)
#model.compile(optimizer='sgd',loss='mse', metrics=[iou])

def Mask_road(mask, THR=0.2):
  M,N=mask.shape[0], mask.shape[1]
  new_mask=np.zeros((M,N))
  # check bottom road position
  i, j=M-5, 0
  while (j<N-1)*(mask[i,j]<THR):
    j+=1

  if j<N//2: #    scenario 1 road on the right
    for i in range(M//3, M): #i=rows
      j1, j2 =-1,-1
      j=0
      while (j<N-1)*(j1<0)*(mask[i,j]<THR):
        j+=1
      j1=j
      j=min(j1+10, N-1)
      while (j<N-1)*(j2<0)*(mask[i,j]<THR):
        j+=1
      j2=j
      new_mask[i,j1:j2]=1

  else:
    for i in range(M//3, M): #i=rows
      j1, j2 =-1,-1
      # find left line
      j=N-1
      while (j>1)*(j2<0)*(mask[i,j]<THR):
        j-=1
      j2=j
      # find middle line
      j=max(j2-10, 1)
      while (j>0)*(j1<0)*(mask[i,j]<THR):
        j-=1
      j1=j
      new_mask[i,j1:j2]=1

  return new_mask
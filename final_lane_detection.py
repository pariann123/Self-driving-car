# -*- coding: utf-8 -*-
"""final_lane_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rwfdf-Kkxs6DuD1oGeXGIbLl1hcjqhv5
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import numpy as np
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
from PIL import Image
import fnmatch
import random

# sklearn
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

# tensorflow
import tensorflow as tf
import keras
from keras.models import Sequential  # V2 is tensorflow.keras.xxxx, V1 is keras.xxx
from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense
from keras.optimizers import Adam
from keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.python.keras import regularizers
from imgaug import augmenters as img_aug
from imgaug import augmenters as iaa
# from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, BatchNormalization, MaxPooling2D

from google.colab import drive
drive.mount('/content/drive')
images_dir = '/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/data/training_data/training_data'
file_list = os.listdir(images_dir)
df = pd.read_csv('/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/data/training_norm.csv')

images_test_dir = '/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/data/test_data/test_data'
file_test_list = os.listdir(images_test_dir)

# This gives us two lists: new_file_list constains the images in muddled up order, angles list provides the angles in the same order as the images in new_file_data so that each data entry corresponds to each  other
angles = []
speeds = []
new_file_list=[]
substring = '(1)'
substring2= '.DS_Store'
pattern = "*.png"
image_paths=[]
for filee in file_list:
  if substring in filee:
    del filee
  elif substring2 in filee:
    del filee
  else:
    new_file_list.append(filee)

for filee in new_file_list:
  if fnmatch.fnmatch(filee, pattern):
    image_paths.append(os.path.join(images_dir,filee))
    filee = int(filee.replace('.png',''))
    index =df[df['image_id']==filee].index.values
    angle = df.loc[index[0],'angle'] #finds the angle relating to the index of the image 
    speed = df.loc[index[0],'speed']
    angles.append(angle)
    speeds.append(speed)

new_file_test_list=[]
image_test_paths=[]
for filee in file_test_list:
    new_file_test_list.append(filee)

for filee in new_file_test_list:
  if fnmatch.fnmatch(filee, pattern):
    image_test_paths.append(os.path.join(images_test_dir,filee))

#Now we have two parallel lists: new_file_list and angles

y=list(zip(angles, speeds))

image_index = random.randint(0,len(angles)-1)
plt.imshow(Image.open(f'/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/data/training_data/training_data/{new_file_list[image_index]}'))
print('image: ', new_file_list[image_index])
print('angle',angles[image_index])
print('speed',speeds[image_index])

X_train, X_valid, y_train, y_valid = train_test_split(image_paths, y, test_size=0.2)
print("Training data: %d\nValidation data: %d" % (len(X_train), len(X_valid)))

def image_preprocessing(image):

  height = image.shape[0]
  image = image[int(height/3):,:,:] #remove half top of the image
  image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # YUV color for Nvidia model
  image = cv2.GaussianBlur(image, (3,3), 0) #reduce noise
  image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model
  return image

#visualise preprocessing on 1 image
image = image_paths[1]
original_image = mpimg.imread(image)  #read path and make into image
image = mpimg.imread(image)
preprocessed_image = image_preprocessing(image)
fig, axis =plt.subplots(1,2, figsize=(15,10))
fig.tight_layout()
axis[0].imshow(original_image)
axis[0].set_title('original image')
axis[1].imshow(preprocessed_image)
axis[1].set_title('preprocessed image')

"""#Augmentation"""

image = X_train[0]
image = mpimg.imread(image)

image.min()

noisy_image = np.copy(image)
n = int(0.005 *image.size)
x = random.choices([i for i in range(240)],k=n)
y = random.choices([i for i in range(320)],k=n)
for i,j in zip(x,y):
  noisy_image[i,j] = noisy_image[i,j]-1
  noisy_image[i,j]=max(noisy_image[i,j].any(), 0)

plt.imshow(noisy_image)

noisy_image.max()

def zoom(image):
  zoom = iaa.Affine(scale=(1,1.3)) #zoom from nothing to 30%
  image = zoom.augment_image(image)
  return image

def pan(image):
  pan = iaa.Affine(translate_percent= {"x" : (-0.1, 0.1), "y": (-0.1, 0.1)})
  image = pan.augment_image(image)
  return image

def brightness(image):
    brightness = iaa.Multiply((0.2, 1.2))
    image = brightness.augment_image(image)
    return image

def flip(image, steering_angle): #steering angle needs to be flipped, but not speed
    image = cv2.flip(image,1)
    steering_angle = 1-steering_angle[0], steering_angle[1]
    return image, steering_angle

def blur(image):
    kernel_size = random.randint(1, 5)  # kernel larger than 5 would make the image way too blurry
    image = cv2.blur(image,(kernel_size, kernel_size))
    return image

def invert(image):
  invert = iaa.Invert(0.5)
  image = invert.augment_image(image)
  return image

# def crop(image):
#   crop = iaa.Crop(percent=(0, 0.3)) # crop image
#   image = crop.augment_image(image) 
#   return image

def sharpen(image):
  sharpen = iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0))
  image = sharpen.augment_image(image)
  return image

def emboss(image):
  emboss = iaa.Emboss(alpha=(0.0, 1.0), strength=(0.5, 1.5))
  image = emboss.augment_image(image)
  return image

def noise(image):
  noisy_image = np.copy(image)
  n = int(0.005 *image.size)
  x = random.choices([i for i in range(240)],k=n)
  y = random.choices([i for i in range(320)],k=n)
  for i,j in zip(x,y):
    noisy_image[i,j] = noisy_image[i,j]-1
    noisy_image[i,j]=max(noisy_image[i,j].any(), 0)

  return noisy_image

def random_augment(image, steering_angle):
    image = mpimg.imread(image)
    if np.random.rand() < 0.5:
      image = pan(image)
    # if np.random.rand() < 0.5:
    #   image = zoom(image)
    if np.random.rand() < 0.5:
      image = brightness(image)
    if np.random.rand() < 0.5:
      image, steering_angle = flip(image, steering_angle)
    # if np.random.rand() < 0.5:
    #   image = crop(image)
    if np.random.rand() < 0.5:
      image = invert(image)
    if np.random.rand() < 0.5:
      image = blur(image)
    if np.random.rand() < 0.5:
      image = sharpen(image)
    if np.random.rand() < 0.5:
      image = emboss(image)
    if np.random.rand() < 0.5:
      image = noise(image)
    return image, steering_angle

def batch_generator(image_path, steering_ang, batch_size, istraining):
  
  while True:
    batch_img = []
    batch_steering = []
    
    for i in range(batch_size):
      random_index = random.randint(0, len(image_path) - 1)
      
      if istraining:
        im, steering = random_augment(image_path[random_index], steering_ang[random_index])

      else:
        im = mpimg.imread(image_path[random_index])
        steering = steering_ang[random_index]
      im = image_preprocessing(im)
      batch_img.append(im)
      batch_steering.append(steering)
    yield (np.asarray(batch_img), np.asarray(batch_steering))

def batch_generator_test(image_path):

  batch_test_img = []

  for i in range(len(image_path)):

    im = mpimg.imread(image_path[i])  
    im = image_preprocessing(im)
    batch_test_img.append(im)
  return (np.asarray(batch_test_img))

"""# Neural Network: Nvidia Model"""

def nvidia_model():
  model = Sequential()
  model.add(Conv2D(24, kernel_size= (5,5), strides=(2,2), input_shape=(66,200,3), activation='elu'))
  model.add(Conv2D(36, kernel_size= (5,5), strides=(2,2), activation='elu'))
  model.add(Conv2D(48, kernel_size= (5,5), strides=(2,2), activation='elu'))
  model.add(Conv2D(64, kernel_size= (3,3), activation='elu'))
  model.add(Dropout(0.2)) #randomly turn 20% of inputs into 0
  model.add(Conv2D(64, kernel_size= (3,3), activation='elu'))
  

  model.add(Flatten())
  model.add(Dense(100,activation='elu'))
  model.add(Dropout(0.2))
  model.add(Dense(50,activation='elu'))
  model.add(Dense(10,activation='elu'))
  model.add(Dense(2)) #outputs the proposed steering angle and speed

  optimizer = Adam(lr=1e-3) # lr is learning rate
  model.compile(loss='mse', optimizer=optimizer)

  return model

model = nvidia_model()

history = model.fit(batch_generator(X_train, y_train, 200, 1),
                                  steps_per_epoch=300, 
                                  epochs=14,
                                  validation_data=batch_generator(X_valid, y_valid, 100, 0),
                                  validation_steps=200,
                                  verbose=1,   
                                  shuffle = 1)

model.save('/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/two_outputs12.h5')
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='validation loss')
plt.legend()

"""Model performance"""

from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score

def summarize_prediction(Y_true, Y_pred):
    
    mse = mean_squared_error(Y_true, Y_pred)
    r_squared = r2_score(Y_true, Y_pred)
    
    print(f'mse       = {mse:.2}')
    print(f'r_squared = {r_squared:.2%}')
    
def predict_and_summarize(X, Y):
    model = load_model('/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/two_outputs12.h5')
    Y_pred = model.predict(X)

    summarize_prediction(Y, Y_pred)
    return Y_pred

X_test, y_test = next(batch_generator(X_valid, y_valid, 10, False))
y_pred = predict_and_summarize(X_test, y_test)

n_tests_show = 2
fig, axes = plt.subplots(n_tests_show, 1, figsize=(10, 4 * n_tests_show))
for i in range(n_tests_show):
    axes[i].imshow(X_test[i])
    axes[i].set_title(f"actual angle={y_test[i]}, predicted angle={y_pred[i]}, diff = {abs(y_pred[i]-y_test[i])}")

"""Predictions"""

def predict_and_summarize(X):
    model = load_model('/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/two_outputs12.h5')
    Y_pred = model.predict(X)

    return Y_pred
X_test=batch_generator_test(image_test_paths)
y_pred = predict_and_summarize(X_test)

y_pred0= []
y_pred1=[]
for i in y_pred:
  if i[1]>=0.5:
    y_pred1.append(1)
  else:
    y_pred1.append(0)

  y_pred0.append(i[0])

substring = '/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/data/test_data/test_data/'
substring2 = '.png'
image_id =[]
for image in image_test_paths:
  image = image.replace(substring,'')
  image = image.replace(substring2,'')
  image_id.append(image)

"""Save data"""

df_csv=pd.DataFrame(list(zip(image_id, y_pred0,y_pred1)),
              columns=['image_id','angle','speed'])

df_csv.to_csv(r'/content/drive/My Drive/MSc Computational Neuroscience, Cognition & AI/MLis2/ML Project/code/two_outputs12_predictions.csv', index = False)

